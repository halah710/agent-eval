# 工程面试选题：对话类 AI Agent 评测系统

## 背景

随着 AI Agent 在各类产品中的应用越来越广泛，如何系统性地评估 Agent 的表现成为关键工程挑战。本选题要求你为**游戏 NPC 对话系统**设计并实现一套自动化评测框架。

在开始之前，请务必仔细阅读 Anthropic 的这篇技术博客，它将为你提供 Agent 评测的核心概念和最佳实践：

**必读材料**：[Demystifying evals for AI agents](https://www.anthropic.com/engineering/demystifying-evals-for-ai-agents)

---

## 业务场景

你所在的游戏公司开发了一款带有 AI NPC 的游戏。玩家可以与 NPC 进行自由对话，NPC 需要：
- 保持角色设定的一致性（性格、口吻、态度）
- 提供自然、有趣的互动体验

目前团队依赖人工测试，效率低且难以追踪回归。你的任务是构建一套**自动化评测系统**，让团队能够：
- 在每次模型/Prompt 迭代后快速验证效果
- 量化对话质量，发现问题并指导优化
- 积累测试用例，防止回归

---

## 核心要求

### 0. 被测系统（Mock NPC）

为了让评测系统能够运行和验证，你需要实现一个**简单的 NPC 对话能力**作为被测对象。

> ⚠️ **重要提示**：这个 NPC 本身**不是考察重点**，可以非常简单（比如直接调用 LLM API + 基础 Prompt）。它的作用是让你的评测系统有东西可测。请把主要精力放在评测系统的设计与实现上。

### 1. 评测框架设计与实现（重点）

构建一个可运行的评测系统，需要包含以下核心能力：

**a) 多轮对话评测**
- 系统需要能够模拟玩家与 NPC 进行多轮对话
- 思考：如何让"模拟玩家"的行为足够真实和多样？

**b) 自动化评分**
- 对话结束后，系统需要自动给出评分
- 评分需要有依据（evidence），而非黑盒打分
- 思考：参考文章中的 grader 类型，什么方式最适合评估"对话质量"这类主观指标？

**c) 测试用例管理**
- 设计合理的数据结构来定义测试场景
- 考虑不同类型的对话场景（如：日常陪伴、情绪倾诉、观点冲突等）

**d) 结果输出与分析**
- 输出结构化的评测报告
- 支持查看低分样例的完整对话记录，便于问题定位

**e) 通用性与可扩展性**
- 评测系统应该与被测系统**解耦**
- 思考：如果未来要接入不同的 NPC 实现（不同模型、不同架构、甚至非 LLM 方案），你的评测系统需要改动多少？
- 目标：被测系统是可替换的"黑盒"，评测系统不应依赖其内部实现

### 2. 评测维度

至少覆盖以下两个维度（可自行扩展）：

| 维度 | 说明 |
|------|------|
| **角色一致性** | NPC 的回复是否符合人设？口吻、态度、价值观是否自洽？ |
| **互动质量** | 对话是否自然流畅？是否能让玩家想继续聊下去？ |

### 3. 技术约束

- 编程语言不限（Python/TypeScript/Go 等均可）
- 可以使用任意 LLM API（OpenAI、Anthropic、本地模型等）
- 需要提供清晰的运行说明

### 4. 关于 AI 编程工具的使用

我们**强烈鼓励**你在开发过程中使用 AI 编程工具（如 GitHub Copilot、Cursor、Claude Code 等）。

> 💡 在我们看来，善用 AI 工具是现代工程师的**核心能力**。2-3 天的时限是基于"合理使用 AI 工具"来设定的。如果你能展示出对 AI 工具的高效使用——比如用它加速原型开发、生成测试用例、辅助调试等——这将是**加分项**。
>
> 当然，我们期望你能理解和把控 AI 生成的代码，并能在后续面试中解释你的设计决策。

---

## 交付物

请在 **2-3 天** 内提交以下内容：

### 必须提交

1. **代码仓库**
   - 完整可运行的评测系统代码
   - 清晰的目录结构和代码注释

2. **README 文档**
   - 系统架构说明
   - 环境配置与运行方式
   - 核心设计决策的说明（为什么这样设计？）

3. **示例评测报告**
   - 至少包含 5 个不同场景的评测结果
   - 展示评分、证据、完整对话记录

### 加分项

- 支持并发执行多个测试用例
- 提供简单的可视化界面查看结果
- 考虑评测环境的隔离性和可复现性
- 设计可扩展的 grader 插件机制

---

## 评估标准

| 维度 | 权重 | 说明 |
|------|------|------|
| **概念理解** | 20% | 是否正确理解 Agent 评测的核心挑战，设计是否合理 |
| **工程质量** | 25% | 代码结构、可读性、错误处理、可维护性 |
| **通用性设计** | 20% | 评测系统与被测系统的解耦程度，能否轻松替换被测对象 |
| **系统完整性** | 20% | 是否能端到端跑通，输出是否有价值 |
| **文档质量** | 10% | README 是否清晰，设计决策是否有说服力 |
| **创新与扩展** | 5% | 是否有超出基本要求的思考和实现 |

---

## 提示与建议

1. **先读文章**：必读材料中包含了大量实践经验，包括：
   - 不同类型 grader 的优缺点
   - 如何处理 non-determinism
   - 如何设计 unambiguous tasks
   - Capability eval vs Regression eval 的区别

2. **从简单开始**：先实现一个最小可用版本（如：单个场景、单轮评测），验证流程跑通后再扩展

3. **关注可复现性**：评测结果应该是可复现的，思考如何控制随机性

4. **重视 transcript**：完整的对话记录是调试和分析的关键，确保保存和展示

5. **评分要有依据**：避免"黑盒"打分，评分应该能追溯到具体的对话内容

---

## 问题与沟通

如果对需求有疑问，请通过 xiaolong@bauhinia.ai 提问。我们鼓励在开始前澄清任何不明确的地方，但请尽量在一封邮件中列明所有的问题。

**注意**：本选题重点考察的是你的**系统设计能力**和**工程实现能力**，而非对特定 LLM API 的熟悉程度。请把时间花在架构设计和核心逻辑上。

---

祝你顺利！
